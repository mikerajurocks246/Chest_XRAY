{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from csv import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate\n",
    "from keras.layers import Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import MaxPooling2D, Flatten,Conv2D, Dense,BatchNormalization,GlobalAveragePooling2D,Dropout\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet_v2 import ResNet50V2\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = r\"C:\\Users\\ABHINAV\\Downloads\\train-20230326T213916Z-001\\train\\Ground_Truth.csv\"\n",
    "train_img = r\"C:\\Users\\ABHINAV\\Downloads\\train-20230326T213916Z-001\\train\\train images\"\n",
    "test_img = r\"C:\\Users\\ABHINAV\\Downloads\\train-20230326T213916Z-001\\test_images-20230331T075032Z-001\\test_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = (os.listdir(r\"C:\\Users\\ABHINAV\\Downloads\\train-20230326T213916Z-001\\train\\train images\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_equalization(image):\n",
    "    \n",
    "    R, G, B = cv2.split(image)\n",
    "    output1_R = cv2.equalizeHist(R)\n",
    "    output1_G = cv2.equalizeHist(G)\n",
    "    output1_B = cv2.equalizeHist(B)\n",
    "    equ = cv2.merge((output1_R, output1_G, output1_B))\n",
    "    \n",
    "    return equ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y  = []\n",
    "y1 = []\n",
    "df = pd.read_csv(train_csv)\n",
    "for i in range(len(lis)):\n",
    "    if df.iloc[i][0] in lis:\n",
    "        if df.iloc[i][1] == \"No Finding\":\n",
    "            y.append(0)\n",
    "        else:\n",
    "            y.append(1)\n",
    "\n",
    "        img_arr = cv2.imread(train_img+chr(92)+df.iloc[i][0])\n",
    "\n",
    "        resized_img = cv2.resize(img_arr, (224, 224),interpolation = cv2.INTER_CUBIC)\n",
    "        #print(resized_img.shape)\n",
    "        eq_img = image_equalization(resized_img)\n",
    "\n",
    "        y1.append(eq_img.astype(np.float16))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41431875525651807\n"
     ]
    }
   ],
   "source": [
    "count_ap = 0\n",
    "count_disease = 0 # given in ap, if person has any disease\n",
    "for i in range(df.shape[0]):\n",
    "    if df.iloc[i][-1] == \"PA\":\n",
    "        count_ap +=1\n",
    "        if df.iloc[i][1] != \"No Finding\":\n",
    "            count_disease += 1\n",
    "print(count_disease/count_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(y1, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = np.array(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train/=255\n",
    "\n",
    "X_val/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3185\n",
      "(3185, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(X_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not now"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = keras.models.Sequential([ \n",
    "\n",
    "#conv + pool layer 1\n",
    "keras.layers.Conv2D(filters = 32, kernel_size=(4,4), activation = 'leaky_relu',  input_shape=(512, 512, 1)),\n",
    "keras.layers.MaxPooling2D((2,2)), \n",
    "# conv + pool layer 2\n",
    "keras.layers.Conv2D(filters = 64, kernel_size=(4,4), activation = 'leaky_relu', input_shape=(512, 512, 1)),\n",
    "keras.layers.MaxPooling2D((2,2)),\n",
    "\n",
    "# dense\n",
    "keras.layers.Flatten(),\n",
    "keras.layers.Dense(128, activation = 'leaky_relu'),\n",
    "keras.layers.Dropout(0.25),\n",
    "keras.layers.Dense(64, activation = 'leaky_relu'),\n",
    "keras.layers.Dropout(0.25),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Dense(1, activation='softmax')\n",
    "])\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3185, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 231s 2s/step\n"
     ]
    }
   ],
   "source": [
    "model_1 = load_model(r\"C:\\Users\\ABHINAV\\Downloads\\train-20230326T213916Z-001\\CheXpert_DenseNet121_res224.h5\")\n",
    "out1 = model_1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y(arr):\n",
    "    max = -1\n",
    "    id = 0\n",
    "    for i in range(arr.shape[0]):\n",
    "        if arr[i]>max:\n",
    "            max = arr[i]\n",
    "            id = i\n",
    "    if id == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[1.0331949e-11 5.2967995e-02 4.0879318e-01 9.6949965e-01 3.5778505e-03\n",
      " 8.9986980e-07 3.8322914e-02 4.1742545e-02 9.9209678e-01 4.1210537e-08\n",
      " 1.0000000e+00 9.4147184e-13 1.8464064e-02 1.8471157e-03]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(y_train[4])\n",
    "print((out1[4]))\n",
    "print(get_y(out1[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet\n",
    "\n",
    "input_layer = Input(shape = (224, 224, 3))\n",
    "\n",
    "\n",
    "res_base = ResNet50V2(input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\")\n",
    "\n",
    "for layer in res_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_res = res_base(input_layer)\n",
    "model_res = GlobalAveragePooling2D()(model_res)\n",
    "output_res = Flatten()(model_res)\n",
    "\n",
    "x = BatchNormalization()(output_res)\n",
    "x = Dense(256,activation = \"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128,activation = \"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation = \"sigmoid\")(x)\n",
    "resnet = tf.keras.models.Model(inputs = input_layer, outputs = x)\n",
    "resnet.compile(optimizer = \"Adam\", loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(r'C:\\Users\\ABHINAV\\Downloads\\train-20230326T213916Z-001\\cheXnet.h5')\n",
    "\n",
    "# Remove the weights from the last layer\n",
    "model.layers[-1].set_weights([np.zeros_like(w) for w in model.layers[-1].get_weights()])\n",
    "\n",
    "# Save the modified model\n",
    "model.save('my_modified_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# densenet over cheXnet\n",
    "\n",
    "input_layer = Input(shape = (224, 224, 3))\n",
    "\n",
    "densenet_base = DenseNet121(input_shape=(224, 224, 3), weights=r'C:\\Users\\ABHINAV\\Downloads\\train-20230326T213916Z-001\\cheXnet.h5')\n",
    "\n",
    "for layer in densenet_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_densenet = densenet_base(input_layer)\n",
    "model_densenet = GlobalAveragePooling2D()(model_densenet)\n",
    "output_densenet = Flatten()(model_densenet)\n",
    "\n",
    "x = BatchNormalization()(output_densenet)\n",
    "x = Dense(256,activation = \"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128,activation = \"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation = \"sigmoid\")(x)\n",
    "densenet = tf.keras.models.Model(inputs = input_layer, outputs = x)\n",
    "densenet.compile(optimizer = \"Adam\", loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 28s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# google net\n",
    "\n",
    "input_layer = Input(shape = (224, 224, 3))\n",
    "\n",
    "google_base = InceptionV3(input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\")\n",
    "\n",
    "for layer in google_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_google = res_base(input_layer)\n",
    "model_google = GlobalAveragePooling2D()(model_google)\n",
    "output_google = Flatten()(model_google)\n",
    "\n",
    "x = BatchNormalization()(output_google)\n",
    "x = Dense(256,activation = \"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128,activation = \"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation = \"sigmoid\")(x)\n",
    "googlenet = tf.keras.models.Model(inputs = input_layer, outputs = x)\n",
    "googlenet.compile(optimizer = \"Adam\", loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mobile net\n",
    "\n",
    "input_layer = Input(shape = (224, 224, 3))\n",
    "\n",
    "mobilenet_base = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\")\n",
    "\n",
    "for layer in mobilenet_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_mobilenet = mobilenet_base(input_layer)\n",
    "model_mobilenet = GlobalAveragePooling2D()(model_mobilenet)\n",
    "output_mobilenet = Flatten()(model_mobilenet)\n",
    "\n",
    "x = BatchNormalization()(output_mobilenet)\n",
    "x = Dense(256,activation = \"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128,activation = \"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation = \"sigmoid\")(x)\n",
    "mobilenet = tf.keras.models.Model(inputs = input_layer, outputs = x)\n",
    "mobilenet.compile(optimizer = \"Adam\", loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg\n",
    "\n",
    "input_layer = Input(shape = (224, 224, 3))\n",
    "\n",
    "vgg_base = VGG16(input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\")\n",
    "\n",
    "for layer in vgg_base.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model_vgg = vgg_base(input_layer)\n",
    "model_vgg = GlobalAveragePooling2D()(model_vgg)\n",
    "output_vgg = Flatten()(model_vgg)\n",
    "\n",
    "\n",
    "x = BatchNormalization()(output_vgg)\n",
    "x = Dense(256,activation = \"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128,activation = \"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation = \"sigmoid\")(x)\n",
    "vggnet = tf.keras.models.Model(inputs = input_layer, outputs = x)\n",
    "vggnet.compile(optimizer = \"Adam\", loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#densenet\n",
    "\n",
    "input_layer = Input(shape = (224, 224, 3))\n",
    "\n",
    "densenet_base = InceptionV3(input_shape=(224, 224, 3), include_top=False, weights=)\n",
    "\n",
    "for layer in densenet_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_densenet = densenet_base(input_layer)\n",
    "model_densenet = GlobalAveragePooling2D()(model_densenet)\n",
    "output_densenet = Flatten()(model_densenet)\n",
    "\n",
    "x = BatchNormalization()(output_densenet)\n",
    "x = Dense(256,activation = \"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128,activation = \"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation = \"sigmoid\")(x)\n",
    "densenet = tf.keras.models.Model(inputs = input_layer, outputs = x)\n",
    "densenet.compile(optimizer = \"Adam\", loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchxrayvision as xrv\n",
    "import skimage, torch, torchvision\n",
    "\n",
    "model = xrv.models.DenseNet(weights=\"densenet121-res224-nih\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 13s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# combined model\n",
    "input_layer = Input(shape = (256, 256, 3))\n",
    "#first model\n",
    "mobilenet_base = MobileNetV2(input_shape=(256, 256, 3), include_top=False, weights=\"imagenet\")\n",
    "\n",
    "densenet_base = DenseNet169(input_shape=(256, 256, 3), include_top=False, weights=\"imagenet\")\n",
    "\n",
    "vgg_base = VGG16(input_shape=(256, 256, 3), include_top=False, weights=\"imagenet\")\n",
    "\n",
    "for layer in mobilenet_base.layers:\n",
    "    layer.trainable =  False\n",
    "for layer in densenet_base.layers:\n",
    "    layer.trainable = False\n",
    "for layer in vgg_base.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model_mobilenet = mobilenet_base(input_layer)\n",
    "model_mobilenet = GlobalAveragePooling2D()(model_mobilenet)\n",
    "output_mobilenet = Flatten()(model_mobilenet)\n",
    "model_densenet = densenet_base(input_layer)\n",
    "model_densenet = GlobalAveragePooling2D()(model_densenet)\n",
    "output_densenet = Flatten()(model_densenet)\n",
    "model_vgg = densenet_base(input_layer)\n",
    "model_vgg = GlobalAveragePooling2D()(model_vgg)\n",
    "output_vgg = Flatten()(model_vgg)\n",
    "\n",
    "merged = tf.keras.layers.Concatenate()([output_mobilenet, output_densenet,output_vgg])\n",
    "\n",
    "x = BatchNormalization()(merged)\n",
    "x = Dense(256,activation = \"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128,activation = \"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation = \"sigmoid\")(x)\n",
    "stacked_model = tf.keras.models.Model(inputs = input_layer, outputs = x)\n",
    "stacked_model.compile(optimizer = \"Adam\", loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "29084464/29084464 [==============================] - 8s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#densenet121+resnet+googlenet\n",
    "\n",
    "input_layer = Input(shape = (224, 224, 3))\n",
    "#first model\n",
    "googlenet_base = InceptionV3(input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\")\n",
    "\n",
    "densenet_base = DenseNet121(input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\")\n",
    "\n",
    "resnet_base = ResNet50V2(input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\")\n",
    "\n",
    "for layer in googlenet_base.layers:\n",
    "    layer.trainable =  False\n",
    "for layer in densenet_base.layers:\n",
    "    layer.trainable = False\n",
    "for layer in resnet_base.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model_googlenet = googlenet_base(input_layer)\n",
    "model_googlenet = GlobalAveragePooling2D()(model_googlenet)\n",
    "output_googlenet = Flatten()(model_googlenet)\n",
    "model_densenet = densenet_base(input_layer)\n",
    "model_densenet = GlobalAveragePooling2D()(model_densenet)\n",
    "output_densenet = Flatten()(model_densenet)\n",
    "model_resnet = resnet_base(input_layer)\n",
    "model_resnet = GlobalAveragePooling2D()(model_resnet)\n",
    "output_resnet = Flatten()(model_resnet)\n",
    "\n",
    "merged = tf.keras.layers.Concatenate()([output_googlenet, output_densenet,output_resnet])\n",
    "\n",
    "x = BatchNormalization()(merged)\n",
    "x = Dense(256,activation = \"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128,activation = \"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation = \"sigmoid\")(x)\n",
    "stacked_model = tf.keras.models.Model(inputs = input_layer, outputs = x)\n",
    "stacked_model.compile(optimizer = \"Adam\", loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " inception_v3 (Functional)      (None, 5, 5, 2048)   21802784    ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " densenet121 (Functional)       (None, 7, 7, 1024)   7037504     ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " resnet50v2 (Functional)        (None, 7, 7, 2048)   23564800    ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['inception_v3[0][0]']           \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 1024)        0           ['densenet121[0][0]']            \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 2048)        0           ['resnet50v2[0][0]']             \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 1024)         0           ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 2048)         0           ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 5120)         0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]',              \n",
      "                                                                  'flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_94 (BatchN  (None, 5120)        20480       ['concatenate_2[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          1310976     ['batch_normalization_94[0][0]'] \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 256)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_95 (BatchN  (None, 256)         1024        ['dropout[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          32896       ['batch_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            129         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 53,770,593\n",
      "Trainable params: 1,354,753\n",
      "Non-trainable params: 52,415,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "stacked_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_save = ModelCheckpoint('./stacked_model.h5',\n",
    "save_best_only = True,\n",
    "save_weights_only = False,\n",
    "monitor = 'val_loss', \n",
    "mode = 'min', verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7785 - accuracy: 0.5928"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 268). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\sack1net.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\sack1net.hd5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 727s 7s/step - loss: 0.7785 - accuracy: 0.5928 - val_loss: 0.6511 - val_accuracy: 0.6286\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6485 - accuracy: 0.6496"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 268). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\sack1net.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\sack1net.hd5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 735s 7s/step - loss: 0.6485 - accuracy: 0.6496 - val_loss: 0.6319 - val_accuracy: 0.6424\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 631s 6s/step - loss: 0.6165 - accuracy: 0.6791 - val_loss: 0.6307 - val_accuracy: 0.6399\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 632s 6s/step - loss: 0.5843 - accuracy: 0.6992 - val_loss: 0.6393 - val_accuracy: 0.6361\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5430 - accuracy: 0.7338"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 268). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\sack1net.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\sack1net.hd5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 737s 7s/step - loss: 0.5430 - accuracy: 0.7338 - val_loss: 0.6479 - val_accuracy: 0.6449\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5037 - accuracy: 0.7592"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 268). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\sack1net.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\sack1net.hd5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 726s 7s/step - loss: 0.5037 - accuracy: 0.7592 - val_loss: 0.6565 - val_accuracy: 0.6462\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4717 - accuracy: 0.7730"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 268). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\sack1net.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\sack1net.hd5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 761s 8s/step - loss: 0.4717 - accuracy: 0.7730 - val_loss: 0.6820 - val_accuracy: 0.6474\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 613s 6s/step - loss: 0.4347 - accuracy: 0.8000 - val_loss: 0.6965 - val_accuracy: 0.6424\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 608s 6s/step - loss: 0.4033 - accuracy: 0.8173 - val_loss: 0.7652 - val_accuracy: 0.6336\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 618s 6s/step - loss: 0.3744 - accuracy: 0.8377 - val_loss: 0.7737 - val_accuracy: 0.6261\n",
      "Epoch 10: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2234851d330>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=3, verbose=1)\n",
    "mcp_save = ModelCheckpoint('./sack1net.hd5',save_best_only=True,monitor='val_accuracy',mode='max')\n",
    "stacked_model.fit(X_train, y_train,epochs=10, validation_data=(X_val, y_val), callbacks=[early_stop, mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "google = load_model(r\"C:\\Users\\ABHINAV\\Downloads\\train-20230326T213916Z-001\\googlenet.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.8113 - accuracy: 0.5802\n",
      "Epoch 1: val_loss improved from inf to 0.63399, saving model to .\\stacked_model.h5\n",
      "100/100 [==============================] - 1033s 10s/step - loss: 0.8113 - accuracy: 0.5802 - val_loss: 0.6340 - val_accuracy: 0.6487\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6795 - accuracy: 0.6546\n",
      "Epoch 2: val_loss improved from 0.63399 to 0.63013, saving model to .\\stacked_model.h5\n",
      "100/100 [==============================] - 989s 10s/step - loss: 0.6795 - accuracy: 0.6546 - val_loss: 0.6301 - val_accuracy: 0.6600\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6337 - accuracy: 0.6703\n",
      "Epoch 3: val_loss improved from 0.63013 to 0.62387, saving model to .\\stacked_model.h5\n",
      "100/100 [==============================] - 964s 10s/step - loss: 0.6337 - accuracy: 0.6703 - val_loss: 0.6239 - val_accuracy: 0.6587\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5986 - accuracy: 0.7011\n",
      "Epoch 4: val_loss did not improve from 0.62387\n",
      "100/100 [==============================] - 934s 9s/step - loss: 0.5986 - accuracy: 0.7011 - val_loss: 0.6350 - val_accuracy: 0.6838\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5520 - accuracy: 0.7212\n",
      "Epoch 5: val_loss did not improve from 0.62387\n",
      "100/100 [==============================] - 917s 9s/step - loss: 0.5520 - accuracy: 0.7212 - val_loss: 0.6460 - val_accuracy: 0.6550\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5296 - accuracy: 0.7344\n",
      "Epoch 6: val_loss did not improve from 0.62387\n",
      "100/100 [==============================] - 919s 9s/step - loss: 0.5296 - accuracy: 0.7344 - val_loss: 0.6504 - val_accuracy: 0.6474\n",
      "Epoch 6: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x215e7df69e0>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "stacked_model.fit(X_train, y_train,epochs=10, validation_data=(X_val, y_val), callbacks=[early_stop, model_save])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=3, verbose=1)\n",
    "mcp_save = ModelCheckpoint('./densenet.hd5',save_best_only=True,monitor='val_accuracy',mode='max')\n",
    "densenet.fit(X_train, y_train,epochs=10, validation_data=(X_val, y_val), callbacks=[early_stop, mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=3, verbose=1)\n",
    "mcp_save = ModelCheckpoint('./resnet.hd5',save_best_only=True,monitor='val_accuracy',mode='max')\n",
    "resnet.fit(X_train, y_train,epochs=10, validation_data=(X_val, y_val), callbacks=[early_stop, mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.7075 - accuracy: 0.6194"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\mobnet.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\mobnet.hd5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 106s 1s/step - loss: 0.7075 - accuracy: 0.6194 - val_loss: 0.6206 - val_accuracy: 0.6718\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 86s 880ms/step - loss: 0.6653 - accuracy: 0.6353 - val_loss: 0.6253 - val_accuracy: 0.6718\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.6328 - accuracy: 0.6632"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\mobnet.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\mobnet.hd5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 108s 1s/step - loss: 0.6328 - accuracy: 0.6632 - val_loss: 0.6211 - val_accuracy: 0.6743\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 89s 906ms/step - loss: 0.6179 - accuracy: 0.6676 - val_loss: 0.6175 - val_accuracy: 0.6679\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 88s 900ms/step - loss: 0.5790 - accuracy: 0.7021 - val_loss: 0.6323 - val_accuracy: 0.6718\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 92s 938ms/step - loss: 0.5497 - accuracy: 0.7204 - val_loss: 0.6472 - val_accuracy: 0.6539\n",
      "Epoch 6: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2168e3a0970>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=3, verbose=1)\n",
    "mcp_save = ModelCheckpoint('./mobnet.hd5',save_best_only=True,monitor='val_accuracy',mode='max')\n",
    "mobilenet.fit(X_train, y_train,epochs=10, validation_data=(X_val, y_val), callbacks=[early_stop,mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.8108 - accuracy: 0.5948"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\mobnet.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\mobnet.hd5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 706s 7s/step - loss: 0.8108 - accuracy: 0.5948 - val_loss: 0.6823 - val_accuracy: 0.5964\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 716s 7s/step - loss: 0.7253 - accuracy: 0.6024 - val_loss: 0.6885 - val_accuracy: 0.5287\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.6963 - accuracy: 0.6200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\mobnet.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\mobnet.hd5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 740s 8s/step - loss: 0.6963 - accuracy: 0.6200 - val_loss: 0.6658 - val_accuracy: 0.6105\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.6643 - accuracy: 0.6369"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\mobnet.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\mobnet.hd5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 733s 7s/step - loss: 0.6643 - accuracy: 0.6369 - val_loss: 0.6340 - val_accuracy: 0.6590\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.6483 - accuracy: 0.6363"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\mobnet.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\mobnet.hd5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 636s 7s/step - loss: 0.6483 - accuracy: 0.6363 - val_loss: 0.6199 - val_accuracy: 0.6616\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.6202 - accuracy: 0.6657"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\mobnet.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\mobnet.hd5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 612s 6s/step - loss: 0.6202 - accuracy: 0.6657 - val_loss: 0.6129 - val_accuracy: 0.6692\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 604s 6s/step - loss: 0.6154 - accuracy: 0.6683 - val_loss: 0.6132 - val_accuracy: 0.6654\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.6217 - accuracy: 0.6791"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\mobnet.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\mobnet.hd5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 610s 6s/step - loss: 0.6217 - accuracy: 0.6791 - val_loss: 0.6051 - val_accuracy: 0.6743\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 601s 6s/step - loss: 0.5963 - accuracy: 0.6785 - val_loss: 0.6085 - val_accuracy: 0.6743\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 602s 6s/step - loss: 0.5885 - accuracy: 0.6938 - val_loss: 0.6044 - val_accuracy: 0.6641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x216e0fd4580>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=3, verbose=1)\n",
    "mcp_save = ModelCheckpoint('./mobnet.hd5',save_best_only=True,monitor='val_accuracy',mode='max')\n",
    "vggnet.fit(X_train, y_train,epochs=10, validation_data=(X_val, y_val), callbacks=[early_stop,mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.8260 - accuracy: 0.5839"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 54). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\googlenet.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\googlenet.hd5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 248s 2s/step - loss: 0.8260 - accuracy: 0.5839 - val_loss: 0.6195 - val_accuracy: 0.6539\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.7078 - accuracy: 0.6168"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 54). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\googlenet.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\googlenet.hd5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 250s 3s/step - loss: 0.7078 - accuracy: 0.6168 - val_loss: 0.6135 - val_accuracy: 0.6590\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.6514 - accuracy: 0.6590"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 54). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\googlenet.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\googlenet.hd5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 258s 3s/step - loss: 0.6514 - accuracy: 0.6590 - val_loss: 0.6051 - val_accuracy: 0.6833\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.6152 - accuracy: 0.6740"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 54). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\googlenet.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\googlenet.hd5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 265s 3s/step - loss: 0.6152 - accuracy: 0.6740 - val_loss: 0.6118 - val_accuracy: 0.6845\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 244s 2s/step - loss: 0.5877 - accuracy: 0.6983 - val_loss: 0.6114 - val_accuracy: 0.6731\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 247s 3s/step - loss: 0.5520 - accuracy: 0.7290 - val_loss: 0.6198 - val_accuracy: 0.6616\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 248s 3s/step - loss: 0.5331 - accuracy: 0.7370 - val_loss: 0.6351 - val_accuracy: 0.6705\n",
      "Epoch 7: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2169dedacb0>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=3, verbose=1)\n",
    "mcp_save = ModelCheckpoint('./googlenet.hd5',save_best_only=True,monitor='val_accuracy',mode='max')\n",
    "googlenet.fit(X_train, y_train,epochs=10, validation_data=(X_val, y_val), callbacks=[early_stop,mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis2 = os.listdir(test_img)\n",
    "X_test = []\n",
    "for item in lis2:\n",
    "    img = cv2.imread(test_img+chr(92)+item)\n",
    "    resized_img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_CUBIC)\n",
    "    X_test.append(resized_img.astype(np.float16))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "998\n"
     ]
    }
   ],
   "source": [
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)\n",
    "X_test/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 168s 5s/step\n"
     ]
    }
   ],
   "source": [
    "y_out = stacked_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 57s 2s/step\n"
     ]
    }
   ],
   "source": [
    "y_out = google.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 81s 3s/step\n"
     ]
    }
   ],
   "source": [
    "y_out1 = model_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_wts = []\n",
    "for i in range(y_out1.shape[0]):\n",
    "    opt_wts.append(get_y(y_out1[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(opt_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(998, 1)\n",
      "998\n"
     ]
    }
   ],
   "source": [
    "print(y_out.shape)\n",
    "print(len(lis2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis3 = []\n",
    "for i in range(y_out.shape[0]):\n",
    "    if y_out[i] < 0.5:\n",
    "        lis3.append(0)\n",
    "    else:\n",
    "        lis3.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462\n"
     ]
    }
   ],
   "source": [
    "print(sum(lis3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame()\n",
    "df2[\"Image Index\"] = lis2\n",
    "df2[\"Finding Labels\"] = opt_wts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"opt2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77dcf5160e701220027ec5af5974b8ee5098ab85e39dbfa96466c02b651f1813"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
